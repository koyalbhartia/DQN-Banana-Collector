{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/koyal-il/deep-reinforcement-learning/p1_navigation/Banana_Linux/Banana.x86\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "reward: 0.0\n",
      "score: 0.0\n",
      "i 300\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "i=0\n",
    "while True:\n",
    "    i=i+1\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    print('reward:', reward)\n",
    "    print('score:', score)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "print(\"i\",i)    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# from model import QNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=37, action_size=4, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.69\tAverage Score: 0.699\n",
      "Episode 200\tAverage Score: 4.30\tAverage Score: 4.305\n",
      "Episode 300\tAverage Score: 7.230\tAverage Score: 7.23\n",
      "Episode 400\tAverage Score: 10.30Average Score: 10.301\n",
      "Episode 500\tAverage Score: 12.96\tAverage Score: 12.96\n",
      "Episode 501\tAverage Score: 13.02\tAverage Score: 13.02\n",
      "Environment solved in 401 episodes!\tAverage Score: 13.02\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #         state = env.reset()\n",
    "#         score = 0\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        score = 0\n",
    "        state = env_info.vector_observations[0]\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]\n",
    "#             score += reward                                # update the score\n",
    "#             state = next_state\n",
    "#             next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "#             print('avg score',score/(t+1))\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tEpisode Score: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score , np.mean(scores_window)), end=\"\")\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "    env.close()\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:Generating new fontManager, this may take some time...\n",
      "INFO:matplotlib.font_manager:Failed to extract font properties from /usr/share/fonts/truetype/noto/NotoColorEmoji.ttf: In FT2Font: Can not load face.  Unknown file format.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots for episode vs rewards\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
